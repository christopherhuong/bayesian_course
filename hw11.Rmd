---
title: "hw11"
author: "Christopher Huong"
date: "2024-04-20"
output: html_document
---



## 11E1. If an event has probability 0.35, what are the log-odds of this event?


log odds = log(p / (1-p))
```{r}
p = 0.35
log(p / (1-p))
```



## 11E2. If an event has log-odds 3.2, what is the probability of this event?


e^3.2 = p / (1-p)

```{r}
# after some high school algebra
# p =
exp(1)^3.2 / (1+exp(1)^3.2)
```


## 11E3. Suppose that a coefficient in a logistic regression has value 1.7. What does this imply about the proportional change in odds of the outcome


The logit scale = log-odds. So one unit change in x leads to a corresponding change in log-odds of success. So exponentiating the coefficient yields you the change in odds.
```{r}
exp(1.7)
```
One unit change in x leads to a 5.5 times higher odds in outcome y


***

## 11M2. If a coefficient in a Poisson regression has value 1.7, what does this imply about the change in the outcome?


The outcome scale is probability of success, based on expected value lambda, and the log link function is used to link the outcome to the linear model \
Thus, we need to exponentiate the coefficient to get some ratio change in expected value (similar to logistic regression) \
Thus, coefficient of 1.7 corresponds to a 5.5 times higher expected value of y

y ~ dpois(lambda) \
log(lambda) = a+b*x
lambda = e^(a+b*x)



## 11M7. Use quap to construct a quadratic approximate posterior distribution for the chimpanzee model that includes a unique intercept for each actor, m11.4 (page 330). Compare the quadratic approximation to the posterior distribution produced instead from MCMC. Can you explain both the differences and the similarities between the approximate and the MCMC distributions? Relax the prior on the actor intercepts to Normal(0,10). Re-estimate the posterior using both ulam and quap.
Do the differences increase or decrease? Why?



```{r}
library(rethinking)
data("chimpanzees") ; d <- chimpanzees; rm(chimpanzees)
d$treatment <- 1 + d$prosoc_left + 2*d$condition
```

```{r}
m1 <- quap(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a[actor] + b[treatment],
    a[actor] ~ dnorm(0, 1.5),
    b[treatment] ~ dnorm(0, 0.5)
  ),
  data=d
)
```


```{r, warning=F,message=F}
d_list <- list(pulled_left=d$pulled_left,
               actor=d$actor,
               treatment=d$treatment)
m2 <- ulam(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a[actor] + b[treatment],
    a[actor] ~ dnorm(0, 1.5),
    b[treatment] ~ dnorm(0, 0.5)
  ),
  data=d_list,chains=4,cores=4
)
```

```{r}
compare1 <- data.frame(quap_mean = precis(m1,2)$mean,
                       quap_sd = precis(m1,2)$sd,
                       mcmc_mean = precis(m2,2)$mean,
                       mcmc_sd = precis(m2,2)$sd) |> round(2)

compare1 <- cbind(parameter = rownames(precis(m1, 2)), compare1)

compare1
```


Eyeballing the quap estimates and MCMC estimates, they seem relatively similar, given narrow priors. a[2] has the largest magnitude of difference. Can plot


```{r}
post_quap <- extract.samples(m1)
post_mcmc <- extract.samples(m2)
```

```{r}
plot(density(post_quap$a[,2]), lwd=2)
lines(density(post_mcmc$a[,2]), lwd=2,col="red")

```

The mcmc density plot (red) has more weight on more extreme densities (left skew), probably because mcmc has no assumed distribution?


Now with flat priors for the actors

```{r}
m3 <- quap(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a[actor] + b[treatment],
    a[actor] ~ dnorm(0, 10),
    b[treatment] ~ dnorm(0, 0.5)
  ),
  data=d
)
```

```{r,warning=F,message=F}
m4 <- ulam(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a[actor] + b[treatment],
    a[actor] ~ dnorm(0, 10),
    b[treatment] ~ dnorm(0, 0.5)
  ),
  data=d_list,chains=4,cores=4
)
```

```{r}
compare2 <- data.frame(quap_mean = precis(m3,2)$mean,
                       quap_sd = precis(m3,2)$sd,
                       mcmc_mean = precis(m4,2)$mean,
                       mcmc_sd = precis(m4,2)$sd) |> round(2)

compare2 <- cbind(parameter = rownames(precis(m3, 2)), compare1)

compare2
```

The only noticeably different estimates are for a[2] again

```{r}
post_quap2 <- extract.samples(m3)
post_mcmc2 <- extract.samples(m4)
```

```{r}
plot(density(post_quap2$a[,2]), lwd=2)
lines(density(post_mcmc2$a[,2]), lwd=2,col="red")

```

Without regularizing (narrow priors), the data is allowed to dominate the posterior, and we still a very non-normal distribution with the MCMC posterior



***

## H2
```{r,warning=F, message=F}
rm(list=ls())
library(MASS)
data("eagles"); d <- eagles; rm(eagles)

d$P <- ifelse(d$P == "L", 1, 0)
d$A <- ifelse(d$A == "A", 1, 0)
d$V <- ifelse(d$V == "L", 1, 0)
```


```{r}
m1 <- quap(
  alist(
    y ~ dbinom(n, p),
    logit(p) <- a + P*bP + A*bA + V*bV,
    a ~ dnorm(0, 1.5),
    c(bP, bA, bV) ~ dnorm(0, 0.5)
  ), data=d
)


```


```{r, message=F, warning=F}
m2 <- ulam(
  alist(
    y ~ dbinom(n, p),
    logit(p) <- a + P*bP + A*bA + V*bV,
    a ~ dnorm(0, 1.5),
    c(bP, bA, bV) ~ dnorm(0, 0.5)
  ),data=d, chains=4
)
```


```{r}
precis(m1)
precis(m2)

```

(a) Pretty much identical posterior means and CIs for quap and mcmc estimates.


(b) The estimates are on the scale of log-odds. \

The mean estimate for the intercept is not reliability different from zero. This can be interpreted as the average probability of a small-body non-adult pirate on a small-body victim is around 50/50. \

To interpret the other estimates we should extract samples from the posterior and convert to the outcome scale. We will use the quap estimates since they're the same

```{r}
post <- extract.samples(m1)

```

Ugliest for loop of all time
```{r}
posterior <- list()
for(i in 1:8){
  a <- as.matrix(post)
  b <- as.matrix(d[i, 3:5])
  c <- matrix(0, ncol=4, nrow=nrow(post))
    for(v in 1:3){
    c[, 1] <- a[, 1]
    c[, (v+1)] <- a[, (v+1)] * b[, v]
    }
  posterior[[i]] <- inv_logit(rowSums(c))
}

```


```{r}
estimates <- matrix(0, ncol=2, nrow=nrow(d))
colnames(estimates) <- c("means", "sd")
for(i in 1:8){
  estimates[i, 1] <- mean(posterior[[i]])
}

for(i in 1:8){
  estimates[i, 2] <- sd(posterior[[i]])
}

estimates <- as.data.frame(estimates) |> round(2)
```

PROBABILITY OF SUCCESS ESTIMATES FOR EACH COMBINATION OF P + A + V
```{r}
estimates <- cbind(d[, 3:5], estimates)
estimates
```

Large-body adult pirates on small-body victims have highest probability of success (p=0.92), and the inverse has the smallest (p=0.21). This makes sense.


Now plotting posterior predictions
```{r}
postpred <- link(m1)
means <- apply(postpred, 2, mean)
ci <- apply(postpred, 2, PI)

```

```{r}
plot(d$y/d$n , ylab="prob of success" , xlab="group" , xaxt="n" , xlim=c(1,8) , pch=16 )
axis(1 , at=1:8 ,labels=c(1:8) )
points(1:8, means)
for(i in 1:8){
  lines(c(i,i) , ci[,i] )
}
```





(c) Add interaction between pirate size and age and compare with WAIC
```{r}
m3 <- quap(
  alist(
    y ~ dbinom(n, p),
    logit(p) <- a + P*bP + A*bA + V*bV + bPA*P*A,
    a ~ dnorm(0, 1.5),
    c(bP, bA, bV, bPA) ~ dnorm(0, 0.5)
  ), data=d
)

```

```{r}
precis(m3)
```


```{r}
compare(m1, m3, func=WAIC)
```

No difference, there does not seem to be a meaningful interaction between pirate age and pirate size












